{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5c75bd-324e-4057-89a4-dcf3d062a045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d2addffa734f6e91f3abea12763712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "Cannot show widget. You probably want to rerun the code cell above (<i>Click in the code cell, and press Shift+Enter <kbd>⇧</kbd>+<kbd>↩</kbd></i>)."
      ],
      "text/plain": [
       "Cannot show ipywidgets in text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code is generated by the Domino Code Assist toolbar button\n",
    "import domino_code_assist as dca\n",
    "dca.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5b59b-dcb9-49c3-a7d5-66db14d5163b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# It Depends Team Model Testing and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940304fe-07ac-4965-b69f-4e699fb11997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edb11161-e5f7-4c9b-83db-abb530e0e198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch   \n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "\n",
    "# Tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import transforms\n",
    "from torch.nn import Module, Conv2d, ConvTranspose2d, Dropout2d, BatchNorm2d\n",
    "from torchvision.datasets import ImageFolder\n",
    "from IPython.display import display, Math, Latex\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a230435-6a4a-49e6-8bfe-4ded3162a2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "type",
     "evalue": "Unknown metric function: 'f1_score'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model = tf.keras.models.load_model(\"itdepends_model.hdf5\") \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_v1.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/saving/saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/saving/legacy/serialization.py:537\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    535\u001b[0m     obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    538\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure you are using a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.utils.custom_object_scope` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand that this object is included in the scope. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         )\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown metric function: 'f1_score'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "# model = tf.keras.models.load_model(\"itdepends_model.hdf5\") \n",
    "model = tf.keras.models.load_model(\"model_v1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2fab25-1855-4614-ac2d-c5b7335579ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_raw = pd.read_csv('/domino/datasets/UPRM_Hackathon_2023/train_data_uprm.csv') # read in training data\n",
    "val_data_raw = pd.read_csv('/domino/datasets/UPRM_Hackathon_2023/val_data_uprm.csv') # read in validation data\n",
    "test_data_raw = pd.read_csv('/domino/datasets/UPRM_Hackathon_2023/test_data_uprm.csv') # read in testing data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c41802-249a-4768-bf61-303a06030570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same data type conversion done before, but this time for test data\n",
    "test_data_raw = test_data_raw.convert_dtypes()\n",
    "test_data_raw ['label'] = test_data_raw['label'].apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f49995df-423f-4f3c-9703-f8445e53712e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config: \n",
    "    img_dimensions = (128, 128)\n",
    "    cls_num = 24\n",
    "    channels = 3 # number of channels in each image (RGB)\n",
    "    images_path = '/domino/datasets/UPRM_Hackathon_2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65ab6f38-948f-4c93-a89d-aa09350dd82a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1505 validated image filenames belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "# test data gen\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_data_raw, \n",
    "                                                x_col = \"image\",\n",
    "                                                y_col = \"label\",\n",
    "                                                target_size=Config.img_dimensions,\n",
    "                                                # batch_size=32,\n",
    "                                                class_mode='categorical',\n",
    "                                                directory='/domino/datasets/UPRM_Hackathon_2023',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "447aaf1c-3d36-4c7e-b988-83a4321fa334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 9s 155ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predict = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3565da8f-7b8f-4a56-bc01-abf3b186643c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 9s 154ms/step - loss: 0.1832 - accuracy: 0.9721 - auc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18323473632335663, 0.9720930457115173, 0.9898346066474915]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24865510-e0fa-4703-ae84-20e68eca71a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predict = np.argmax(test_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ad9b93d-9610-4a63-bf69-0991bfea643d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae3b13e7-29ce-419a-a854-63a0e99f92e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.9619592045222056\n",
      "\u001b[91m\u001b[1m\u001b[4mRecall: Criteria for winning submissions is determined by the F1 score above!\n"
     ]
    }
   ],
   "source": [
    "# cm = confusion_matrix(np.ravel(test_data_raw['label'].to_list()), test_predict)\n",
    "F1_score = f1_score(np.ravel(test_data_raw['label'].to_list()), test_predict, average='macro')\n",
    "\n",
    "print(f'f1_score: {F1_score}')\n",
    "print(f\"{bcolors.FAIL}{bcolors.BOLD}{bcolors.UNDERLINE}Recall: Criteria for winning submissions is determined by the F1 score above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8e1eea9-1243-474e-b861-7b3c5fe296cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<property at 0x7feff80e8130>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9d957-b4da-40bc-9c1a-cfa3cd7cb152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
